namespace FlashBenchData;

enum Platform: byte {
  MXC500 = 0,
  MXC550 = 1,
}

enum GridType: byte {
  NHB = 0,
  NBH,
  HNB,
  BNH,
  BHN,
  HBN,
}

enum BalanceType: byte {
  None = 0,
  Mode1,
}

enum PyApiType: byte {
  FlashAttnFunc = 0,
  FlashAttnQKVPackedFunc,
  FlashAttnKVPackedFunc,
  FlashAttnVarlenQKVPackedFunc,
  FlashAttnVarlenKVPackedFunc,
  FlashAttnVarlenFunc,
  FlashAttnWithKVCache,
}

enum CppApiType: byte {
  FlashFwd = 0,
  FlashVarlenFwd,
  FlashBwd,
  FlashVarlenBwd,
  FlashFwdKvcache,
  FlashFwdInfer,
  FlashVarlenFwdInfer,
}

enum KernelType: byte {
  Fwd = 0,
  FwdSplitkv,
  Bwd,
}

table AttentionSolution {
  head_dim: int32;
  grid_type: GridType;
  balance_type: BalanceType;
  num_splits: int32;
  kernel_type: KernelType;
  kernel_id: string;
}

enum DataType: byte {
  float16 = 0,
  bfloat16,
}

table AttentionProblem {
  dtype: DataType;
  head_dim: int32;
  head_dim_v: int32;
  num_heads_q: int32;
  num_heads_kv: int32;
  batch_size: int32;
  seqlens_q: [int32];
  seqlens_kv: [int32];
  total_seqlens_q: int32;
  total_seqlens_kv: int32;
  max_seqlen_q: int32;
  max_seqlen_kv: int32;
  causal: bool;
  dropout: bool;
  alibi: bool;
  window_left: int32;
  window_right: int32;
  attn_mask: bool;
  deterministic: bool;
  paged_kv: bool;
  paged_block_size: int32;
  paged_num_blocks: int32;
  append_kv: bool;
  rope: bool;
  hash_code: string;
  pyapi: PyApiType;
  cppapi: CppApiType;
  solution: AttentionSolution;
}

table AttentionBenchTable {
  problems: [AttentionProblem];
  platform: Platform;
  version: string;
}

root_type AttentionBenchTable;
