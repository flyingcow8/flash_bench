namespace FlashBenchData;

enum GridType: byte {
  NHB = 0,
  NBH,
  HNB,
  BNH,
  BHN,
  HBN,
}

enum BalanceType: byte {
  None = 0,
  Mode1,
}

enum PyApiType: byte {
  FlashAttnFunc = 0,
  FlashAttnQKVPackedFunc,
  FlashAttnKVPackedFunc,
  FlashAttnVarlenQKVPackedFunc,
  FlashAttnVarlenKVPackedFunc,
  FlashAttnVarlenFunc,
  FlashAttnWithKVCache,
}

enum CApiType: byte {
  MhaFwd = 0,
  MhaVarlenFwd,
  MhaBwd,
  MhaVarlenBwd,
  MhaFwdKVCache
}

enum KernelType: byte {
  Fwd = 0,
  FwdSplitkv,
  Bwd,
}

table AttentionSolution {
  head_dim: int32;
  tile_m: int32;
  tile_n: int32;
  num_waves: int32;
  grid_type: GridType;
  blance_type: BalanceType;
  num_splits: int32;
  kernel_type: KernelType;
}

enum DataType: byte {
  float16 = 0,
  bfloat16,
}

enum TAG: byte {
  Deploy = 0,
  TestFwd,
  TestBwd,
}

table AttentionProblem {
  dtype: DataType;
  head_dim: int32;
  num_heads_q: int32;
  num_heads_kv: int32;
  batch_size: int32;
  seqlens_q: [int32];
  seqlens_kv: [int32];
  causal: bool;
  dropout: bool;
  alibi: bool;
  local: bool;
  attn_mask: bool;
  deterministic: bool;
  paged_kv: bool;
  paged_block_size: int32;
  paged_num_blocks: int32;
  append_kv: bool;
  pyapi: PyApiType;
  capi: CApiType;
  is_training: bool;
  solution_fwd: AttentionSolution;
  solution_bwd: AttentionSolution;
}

table AttentionBenchTable {
  problems: [AttentionProblem];
  version: int32;
  tag: TAG;
}

root_type AttentionBenchTable;
